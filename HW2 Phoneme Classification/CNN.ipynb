{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fockspaces/ML2021spring/blob/main/HW2%20Phoneme%20Classification/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2-1 Phoneme Classification**\n",
        "\n",
        "* Slides: https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/hw/HW02/HW02.pdf\n",
        "* Video (Chinese): https://youtu.be/PdjXnQbu2zo\n",
        "* Video (English): https://youtu.be/ESRr-VCykBs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emUd7uS7crTz"
      },
      "source": [
        "## The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus (TIMIT)\n",
        "The TIMIT corpus of reading speech has been designed to provide speech data for the acquisition of acoustic-phonetic knowledge and for the development and evaluation of automatic speech recognition systems.\n",
        "\n",
        "This homework is a multiclass classification task, \n",
        "we are going to train a deep neural network classifier to predict the phonemes for each frame from the speech corpus TIMIT.\n",
        "\n",
        "link: https://academictorrents.com/details/34e2b78745138186976cbc27939b1b34d18bd5b3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "## Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have `timit_11/train_11.npy`, `timit_11/train_label_11.npy`, and `timit_11/test_11.npy` after running this block.<br><br>\n",
        "`timit_11/`\n",
        "- `train_11.npy`: training data<br>\n",
        "- `train_label_11.npy`: training label<br>\n",
        "- `test_11.npy`:  testing data<br><br>\n",
        "\n",
        "**notes: if the google drive link is dead, you can download the data directly from Kaggle and upload it to the workspace**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFqKyrT9mDtM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk_CWeC8mDR0",
        "outputId": "1f28204e-035b-4fe8-d44b-bf8b8c5ab746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkiMEcC3Foq",
        "outputId": "a470fe0f-e4ce-43e6-b9cd-2eb8c1826b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: timit_11/\n",
            "  inflating: timit_11/train_11.npy   \n",
            "  inflating: timit_11/test_11.npy    \n",
            "  inflating: timit_11/train_label_11.npy  \n",
            "data.zip  drive  sample_data  timit_11\n"
          ]
        }
      ],
      "source": [
        "# !gdown --id '1HPkcmQmFGu-3OknddKIa5dNDsR05lIQR' --output data.zip\n",
        "!cp \"/content/drive/MyDrive/timit_11_v2.zip 的副本\" \"data.zip\"\n",
        "!unzip data.zip\n",
        "!ls "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "## Preparing Data\n",
        "Load the training and testing data from the `.npy` file (NumPy array)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJjLT8em-y9G",
        "outputId": "a19e73ca-fd54-4c5a-9338-3ba9c113b690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data ...\n",
            "Size of training data: (1229932, 429)\n",
            "Size of testing data: (451552, 429)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print('Loading data ...')\n",
        "\n",
        "data_root='./timit_11/'\n",
        "train = np.load(data_root + 'train_11.npy')\n",
        "train_label = np.load(data_root + 'train_label_11.npy')\n",
        "test = np.load(data_root + 'test_11.npy')\n",
        "\n",
        "\n",
        "print('Size of training data: {}'.format(train.shape))\n",
        "print('Size of testing data: {}'.format(test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WB9xXUlIqAT"
      },
      "outputs": [],
      "source": [
        "def sample(data, stride):\n",
        "  base = data.copy()\n",
        "  for step in range(1, stride+1, 1):\n",
        "    Rshift = np.roll(base,step,axis=0)\n",
        "    data = np.concatenate((Rshift,data), axis=1)\n",
        "  for step in range(-1, -1-1*stride, -1):\n",
        "    Lshift = np.roll(base,step,axis=0)\n",
        "    data = np.concatenate((data,Lshift), axis=1)\n",
        "\n",
        "  data = np.reshape(data, (-1,2*stride+1,39))\n",
        "  return data\n",
        "\n",
        "def normalize(data):\n",
        "  mean = np.mean(data, axis=0)\n",
        "  std = np.std(data, axis=0)\n",
        "  return (data - mean)/std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN_80nqvjOrq"
      },
      "outputs": [],
      "source": [
        "# # normalize data\n",
        "# train = normalize(train)\n",
        "# test = normalize(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_0i5dpHQPBu"
      },
      "outputs": [],
      "source": [
        "stride = 25\n",
        "# (,429)split to(11,39)\n",
        "train = np.reshape(train, (-1,11,39))\n",
        "test = np.reshape(test, (-1,11,39))\n",
        "\n",
        "# pick only the 5th MFCC which is corresponding to the label\n",
        "train = train[:,5,:]\n",
        "test = test[:,5,:]\n",
        "\n",
        "# include nearby MFCC (To extend the frame length)\n",
        "train = sample(train, stride)\n",
        "test = sample(test, stride)\n",
        "\n",
        "# transform to 4d input array (with kernel)\n",
        "train = np.reshape(train, (-1,1,(2*stride+1),39))\n",
        "test = np.reshape(test, (-1,1,(2*stride+1),39))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsKh0UbeO5VY",
        "outputId": "76626052-dfd0-4695-82a0-13d583e6613d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1229932, 1, 51, 39)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "siKG6cmMepVv",
        "outputId": "c7fee721-850d-494c-c730-7a2fd3165024"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "mfcc = np.reshape(train[0], ((2*stride+1),39))\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "ax.imshow(mfcc);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TIMITDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(np.int)\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIC6WhGeh9v"
      },
      "source": [
        "Split the labeled data into a training set and a validation set, you can modify the variable `VAL_RATIO` to change the ratio of validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYqi_lAuvC59"
      },
      "outputs": [],
      "source": [
        "VAL_RATIO = 0\n",
        "\n",
        "percent = int(train.shape[0] * (1 - VAL_RATIO))\n",
        "# train_x, train_y, val_x, val_y = train[:], train_label[:], train[percent:], train_label[percent:]\n",
        "val_x, val_y = train[percent:], train_label[percent:]\n",
        "# print('Size of training set: {}'.format(train_x.shape))\n",
        "# print('Size of validation set: {}'.format(val_x.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E04qGvVN212c"
      },
      "outputs": [],
      "source": [
        "# train_x = train_x.reshape(train_x.shape[0], 1, train_x.shape[1], -1)\n",
        "# test_x = test.reshape(test.shape[0], 1, test.shape[1], -1)\n",
        "# train_x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbCfclUIgMTX"
      },
      "source": [
        "Create a data loader from the dataset, feel free to tweak the variable `BATCH_SIZE` here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUCbQvqJurYc",
        "outputId": "a2746c96-52d7-4f64-e9da-7a67e394cc59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 1024\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_set = TIMITDataset(train, train_label)\n",
        "val_set = TIMITDataset(val_x, val_y)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SY7X0lUgb50"
      },
      "source": [
        "Cleanup the unneeded variables to save memory.<br>\n",
        "\n",
        "**notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later<br>the data size is quite huge, so be aware of memory usage in colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8rzkGraeYeN",
        "outputId": "b123297f-2a69-438c-f48c-7d98ddf0f58c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "del train, train_label, val_x, val_y\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYr1ng5fh9pA"
      },
      "source": [
        "Define model architecture, you are encouraged to change and experiment with the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbZrwT6Ny0XL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(429, 1024)\n",
        "        self.layer2 = nn.Linear(1024, 512)\n",
        "        self.layer3 = nn.Linear(512, 128)\n",
        "        self.out = nn.Linear(128, 39) \n",
        "\n",
        "        self.act_fn = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.act_fn(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.act_fn(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.act_fn(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfJfs6CcXZZj"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # The arguments for commonly used modules:\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "\n",
        "        # input image size: [1, num, 29]\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            #1st\n",
        "            nn.Conv2d(1, 32, 3, 1, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            \n",
        "            #2nd\n",
        "            nn.Conv2d(32, 32, 5, 1, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "\n",
        "            #3rd\n",
        "            nn.Conv2d(32, 64, 5, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #4th\n",
        "            nn.Conv2d(64, 64, 5, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "\n",
        "            #5th\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #6th\n",
        "            nn.Conv2d(128, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "            nn.Dropout(0.25),\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(216 * 8*8, 128),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 39)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input (x): [batch_size, 3, 128, 128]\n",
        "        # output: [batch_size, 11]\n",
        "\n",
        "        # Extract features by convolutional layers.\n",
        "        x = self.cnn_layers(x)\n",
        "\n",
        "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
        "        x = x.flatten(1)\n",
        "\n",
        "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
        "        x = self.fc_layers(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRYciXZvPbYh"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y114Vmm3Ja6o"
      },
      "outputs": [],
      "source": [
        "#check device\n",
        "def get_device():\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEX-yjHjhGuH"
      },
      "source": [
        "Fix random seeds for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88xPiUnm0tAd"
      },
      "outputs": [],
      "source": [
        "# fix random seed\n",
        "def same_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbBcBXkSp6RA"
      },
      "source": [
        "Feel free to change the training parameters here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTp3ZXg1yO9Y",
        "outputId": "edc17898-fcad-49e4-aaef-662a10eab432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "# fix random seed for reproducibility\n",
        "same_seeds(0)\n",
        "\n",
        "# get device \n",
        "device = get_device()\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# training parameters\n",
        "num_epoch = 500               # number of training epoch\n",
        "learning_rate = 1e-4       # learning rate\n",
        "\n",
        "# the path where checkpoint saved\n",
        "model_path = './CNNmodel_2.ckpt'\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "model = Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdMWsBs7zzNs",
        "outputId": "7311ace4-64d3-457d-a763-21e3c6bb1c0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/500] Train Acc: 0.513833 Loss: 1.691434\n",
            "[002/500] Train Acc: 0.609419 Loss: 1.283014\n",
            "[003/500] Train Acc: 0.633533 Loss: 1.189353\n",
            "[004/500] Train Acc: 0.647182 Loss: 1.135708\n",
            "[005/500] Train Acc: 0.657011 Loss: 1.098157\n",
            "[006/500] Train Acc: 0.664307 Loss: 1.070914\n",
            "[007/500] Train Acc: 0.670145 Loss: 1.048557\n",
            "[008/500] Train Acc: 0.675385 Loss: 1.027712\n",
            "[009/500] Train Acc: 0.679744 Loss: 1.011562\n",
            "[010/500] Train Acc: 0.683445 Loss: 0.996809\n",
            "[011/500] Train Acc: 0.687220 Loss: 0.984208\n",
            "[012/500] Train Acc: 0.690148 Loss: 0.972104\n",
            "[013/500] Train Acc: 0.692888 Loss: 0.960707\n",
            "[014/500] Train Acc: 0.695313 Loss: 0.951323\n",
            "[015/500] Train Acc: 0.697793 Loss: 0.942410\n",
            "[016/500] Train Acc: 0.699849 Loss: 0.935776\n",
            "[017/500] Train Acc: 0.701875 Loss: 0.926810\n",
            "[018/500] Train Acc: 0.704202 Loss: 0.918113\n",
            "[019/500] Train Acc: 0.705961 Loss: 0.910830\n",
            "[020/500] Train Acc: 0.708006 Loss: 0.904276\n",
            "[021/500] Train Acc: 0.709437 Loss: 0.899351\n",
            "[022/500] Train Acc: 0.711242 Loss: 0.891641\n",
            "[023/500] Train Acc: 0.712448 Loss: 0.887300\n",
            "[024/500] Train Acc: 0.713783 Loss: 0.882848\n",
            "[025/500] Train Acc: 0.715409 Loss: 0.877150\n",
            "[026/500] Train Acc: 0.715918 Loss: 0.872872\n",
            "[027/500] Train Acc: 0.717133 Loss: 0.868392\n",
            "[028/500] Train Acc: 0.718846 Loss: 0.863253\n",
            "[029/500] Train Acc: 0.720222 Loss: 0.857606\n",
            "[030/500] Train Acc: 0.721768 Loss: 0.853369\n",
            "[031/500] Train Acc: 0.722585 Loss: 0.849017\n",
            "[032/500] Train Acc: 0.724216 Loss: 0.843470\n",
            "[033/500] Train Acc: 0.725796 Loss: 0.838842\n",
            "[034/500] Train Acc: 0.726410 Loss: 0.836175\n",
            "[035/500] Train Acc: 0.727713 Loss: 0.831599\n",
            "[036/500] Train Acc: 0.734004 Loss: 0.809601\n",
            "[037/500] Train Acc: 0.734635 Loss: 0.807077\n",
            "[038/500] Train Acc: 0.735443 Loss: 0.805956\n",
            "[039/500] Train Acc: 0.734902 Loss: 0.806348\n",
            "[040/500] Train Acc: 0.736147 Loss: 0.804052\n",
            "[041/500] Train Acc: 0.735144 Loss: 0.805098\n",
            "[042/500] Train Acc: 0.735102 Loss: 0.804208\n",
            "[043/500] Train Acc: 0.735124 Loss: 0.804731\n",
            "[044/500] Train Acc: 0.735024 Loss: 0.804677\n",
            "[045/500] Train Acc: 0.735739 Loss: 0.803595\n",
            "[046/500] Train Acc: 0.736332 Loss: 0.802805\n",
            "[047/500] Train Acc: 0.735922 Loss: 0.802405\n",
            "[048/500] Train Acc: 0.735649 Loss: 0.802225\n",
            "[049/500] Train Acc: 0.735859 Loss: 0.802478\n",
            "[050/500] Train Acc: 0.736302 Loss: 0.800931\n",
            "[051/500] Train Acc: 0.736055 Loss: 0.802172\n",
            "[052/500] Train Acc: 0.735498 Loss: 0.803392\n",
            "[053/500] Train Acc: 0.736633 Loss: 0.800553\n",
            "[054/500] Train Acc: 0.736132 Loss: 0.801999\n",
            "[055/500] Train Acc: 0.737041 Loss: 0.800081\n",
            "[056/500] Train Acc: 0.737041 Loss: 0.799397\n",
            "[057/500] Train Acc: 0.736613 Loss: 0.800543\n",
            "[058/500] Train Acc: 0.736904 Loss: 0.800486\n",
            "[059/500] Train Acc: 0.736794 Loss: 0.799997\n",
            "[060/500] Train Acc: 0.736433 Loss: 0.800630\n",
            "[061/500] Train Acc: 0.737029 Loss: 0.798823\n",
            "[062/500] Train Acc: 0.737242 Loss: 0.799607\n",
            "[063/500] Train Acc: 0.737436 Loss: 0.798407\n",
            "[064/500] Train Acc: 0.736823 Loss: 0.799178\n",
            "[065/500] Train Acc: 0.736996 Loss: 0.799109\n",
            "[066/500] Train Acc: 0.737389 Loss: 0.798251\n",
            "[067/500] Train Acc: 0.737283 Loss: 0.798305\n",
            "[068/500] Train Acc: 0.737242 Loss: 0.798132\n",
            "[069/500] Train Acc: 0.737445 Loss: 0.798171\n",
            "[070/500] Train Acc: 0.737216 Loss: 0.798822\n",
            "[071/500] Train Acc: 0.737448 Loss: 0.797556\n",
            "[072/500] Train Acc: 0.737552 Loss: 0.798481\n",
            "[073/500] Train Acc: 0.737984 Loss: 0.797669\n",
            "[074/500] Train Acc: 0.737442 Loss: 0.797229\n",
            "[075/500] Train Acc: 0.737717 Loss: 0.796894\n",
            "[076/500] Train Acc: 0.737446 Loss: 0.796728\n",
            "[077/500] Train Acc: 0.737593 Loss: 0.796754\n",
            "[078/500] Train Acc: 0.737963 Loss: 0.796001\n",
            "[079/500] Train Acc: 0.737429 Loss: 0.797275\n",
            "[080/500] Train Acc: 0.737508 Loss: 0.796023\n",
            "[081/500] Train Acc: 0.737599 Loss: 0.797013\n",
            "[082/500] Train Acc: 0.737789 Loss: 0.795602\n",
            "[083/500] Train Acc: 0.738204 Loss: 0.795490\n",
            "[084/500] Train Acc: 0.738031 Loss: 0.795991\n",
            "[085/500] Train Acc: 0.738112 Loss: 0.795678\n",
            "[086/500] Train Acc: 0.738308 Loss: 0.795812\n",
            "[087/500] Train Acc: 0.737993 Loss: 0.795686\n",
            "[088/500] Train Acc: 0.738594 Loss: 0.793782\n",
            "[089/500] Train Acc: 0.738591 Loss: 0.794293\n",
            "[090/500] Train Acc: 0.737862 Loss: 0.795170\n",
            "[091/500] Train Acc: 0.738308 Loss: 0.794953\n",
            "[092/500] Train Acc: 0.738138 Loss: 0.794449\n",
            "[093/500] Train Acc: 0.738291 Loss: 0.794127\n",
            "[094/500] Train Acc: 0.738330 Loss: 0.794158\n",
            "[095/500] Train Acc: 0.738583 Loss: 0.794152\n",
            "[096/500] Train Acc: 0.738655 Loss: 0.793245\n",
            "[097/500] Train Acc: 0.738694 Loss: 0.794064\n",
            "[098/500] Train Acc: 0.738917 Loss: 0.792886\n",
            "[099/500] Train Acc: 0.738724 Loss: 0.792996\n",
            "[100/500] Train Acc: 0.738470 Loss: 0.793565\n",
            "[101/500] Train Acc: 0.738541 Loss: 0.794076\n",
            "[102/500] Train Acc: 0.738451 Loss: 0.793402\n",
            "[103/500] Train Acc: 0.738947 Loss: 0.791723\n",
            "[104/500] Train Acc: 0.738975 Loss: 0.793267\n",
            "[105/500] Train Acc: 0.738569 Loss: 0.792760\n",
            "[106/500] Train Acc: 0.738206 Loss: 0.794515\n",
            "[107/500] Train Acc: 0.738881 Loss: 0.791823\n",
            "[108/500] Train Acc: 0.738903 Loss: 0.792207\n",
            "[109/500] Train Acc: 0.739223 Loss: 0.792388\n",
            "[110/500] Train Acc: 0.738897 Loss: 0.792486\n",
            "[111/500] Train Acc: 0.739244 Loss: 0.792209\n",
            "[112/500] Train Acc: 0.739077 Loss: 0.791412\n",
            "[113/500] Train Acc: 0.739208 Loss: 0.791705\n",
            "[114/500] Train Acc: 0.738998 Loss: 0.791772\n",
            "[115/500] Train Acc: 0.739189 Loss: 0.790504\n",
            "[116/500] Train Acc: 0.738716 Loss: 0.791265\n",
            "[117/500] Train Acc: 0.739180 Loss: 0.791280\n",
            "[118/500] Train Acc: 0.739563 Loss: 0.791448\n",
            "[119/500] Train Acc: 0.739061 Loss: 0.790799\n",
            "[120/500] Train Acc: 0.739228 Loss: 0.790748\n",
            "[121/500] Train Acc: 0.739978 Loss: 0.789781\n",
            "[122/500] Train Acc: 0.739554 Loss: 0.790295\n",
            "[123/500] Train Acc: 0.739238 Loss: 0.790930\n",
            "[124/500] Train Acc: 0.738952 Loss: 0.791116\n",
            "[125/500] Train Acc: 0.739515 Loss: 0.790054\n",
            "[126/500] Train Acc: 0.739660 Loss: 0.790537\n",
            "[127/500] Train Acc: 0.739112 Loss: 0.790929\n",
            "[128/500] Train Acc: 0.739553 Loss: 0.790118\n",
            "[129/500] Train Acc: 0.739715 Loss: 0.789945\n",
            "[130/500] Train Acc: 0.739072 Loss: 0.790049\n",
            "[131/500] Train Acc: 0.739217 Loss: 0.790678\n",
            "[132/500] Train Acc: 0.740033 Loss: 0.789455\n",
            "[133/500] Train Acc: 0.740215 Loss: 0.788613\n",
            "[134/500] Train Acc: 0.740043 Loss: 0.789919\n",
            "[135/500] Train Acc: 0.739948 Loss: 0.789315\n",
            "[136/500] Train Acc: 0.739882 Loss: 0.789172\n",
            "[137/500] Train Acc: 0.739745 Loss: 0.788890\n",
            "[138/500] Train Acc: 0.740437 Loss: 0.787470\n",
            "[139/500] Train Acc: 0.740191 Loss: 0.787389\n",
            "[140/500] Train Acc: 0.740521 Loss: 0.788021\n",
            "[141/500] Train Acc: 0.740418 Loss: 0.788350\n",
            "[142/500] Train Acc: 0.740071 Loss: 0.787768\n",
            "[143/500] Train Acc: 0.740119 Loss: 0.788230\n",
            "[144/500] Train Acc: 0.740127 Loss: 0.787898\n",
            "[145/500] Train Acc: 0.740256 Loss: 0.787800\n",
            "[146/500] Train Acc: 0.739913 Loss: 0.787924\n",
            "[147/500] Train Acc: 0.739801 Loss: 0.787549\n",
            "[148/500] Train Acc: 0.740504 Loss: 0.787994\n",
            "[149/500] Train Acc: 0.740115 Loss: 0.787828\n",
            "[150/500] Train Acc: 0.740530 Loss: 0.787434\n",
            "[151/500] Train Acc: 0.740521 Loss: 0.787528\n",
            "[152/500] Train Acc: 0.740782 Loss: 0.787102\n",
            "[153/500] Train Acc: 0.740389 Loss: 0.786776\n",
            "[154/500] Train Acc: 0.740634 Loss: 0.786730\n",
            "[155/500] Train Acc: 0.739980 Loss: 0.787028\n",
            "[156/500] Train Acc: 0.740639 Loss: 0.786264\n",
            "[157/500] Train Acc: 0.740486 Loss: 0.786731\n",
            "[158/500] Train Acc: 0.740328 Loss: 0.787517\n",
            "[159/500] Train Acc: 0.740736 Loss: 0.787193\n",
            "[160/500] Train Acc: 0.740690 Loss: 0.786471\n",
            "[161/500] Train Acc: 0.741228 Loss: 0.786022\n",
            "[162/500] Train Acc: 0.740631 Loss: 0.786843\n",
            "[163/500] Train Acc: 0.740742 Loss: 0.785731\n",
            "[164/500] Train Acc: 0.740884 Loss: 0.785631\n",
            "[165/500] Train Acc: 0.740552 Loss: 0.785746\n",
            "[166/500] Train Acc: 0.741164 Loss: 0.784956\n",
            "[167/500] Train Acc: 0.741140 Loss: 0.785483\n",
            "[168/500] Train Acc: 0.740712 Loss: 0.785420\n",
            "[169/500] Train Acc: 0.740708 Loss: 0.785703\n",
            "[170/500] Train Acc: 0.740987 Loss: 0.785324\n",
            "[171/500] Train Acc: 0.741248 Loss: 0.784352\n",
            "[172/500] Train Acc: 0.741100 Loss: 0.785389\n",
            "[173/500] Train Acc: 0.741040 Loss: 0.784606\n",
            "[174/500] Train Acc: 0.741549 Loss: 0.784561\n",
            "[175/500] Train Acc: 0.741182 Loss: 0.784921\n",
            "[176/500] Train Acc: 0.741013 Loss: 0.785444\n",
            "[177/500] Train Acc: 0.741099 Loss: 0.785111\n",
            "[178/500] Train Acc: 0.741552 Loss: 0.784472\n",
            "[179/500] Train Acc: 0.741278 Loss: 0.784582\n",
            "[180/500] Train Acc: 0.741008 Loss: 0.784689\n",
            "[181/500] Train Acc: 0.741139 Loss: 0.784380\n",
            "[182/500] Train Acc: 0.740809 Loss: 0.784288\n",
            "[183/500] Train Acc: 0.741984 Loss: 0.782853\n",
            "[184/500] Train Acc: 0.740960 Loss: 0.784455\n",
            "[185/500] Train Acc: 0.741019 Loss: 0.784118\n",
            "[186/500] Train Acc: 0.741198 Loss: 0.784205\n",
            "[187/500] Train Acc: 0.741132 Loss: 0.784856\n",
            "[188/500] Train Acc: 0.741272 Loss: 0.783437\n",
            "[189/500] Train Acc: 0.741511 Loss: 0.783413\n",
            "[190/500] Train Acc: 0.741566 Loss: 0.783286\n",
            "[191/500] Train Acc: 0.741303 Loss: 0.783455\n",
            "[192/500] Train Acc: 0.741560 Loss: 0.782950\n",
            "[193/500] Train Acc: 0.741858 Loss: 0.782174\n",
            "[194/500] Train Acc: 0.741413 Loss: 0.783738\n",
            "[195/500] Train Acc: 0.741258 Loss: 0.783357\n",
            "[196/500] Train Acc: 0.741369 Loss: 0.783097\n",
            "[197/500] Train Acc: 0.741835 Loss: 0.783205\n",
            "[198/500] Train Acc: 0.741690 Loss: 0.783189\n",
            "[199/500] Train Acc: 0.742020 Loss: 0.782197\n",
            "[200/500] Train Acc: 0.741752 Loss: 0.782040\n",
            "[201/500] Train Acc: 0.742132 Loss: 0.781630\n",
            "[202/500] Train Acc: 0.741711 Loss: 0.781834\n",
            "[203/500] Train Acc: 0.741541 Loss: 0.782922\n",
            "[204/500] Train Acc: 0.741643 Loss: 0.782161\n",
            "[205/500] Train Acc: 0.741633 Loss: 0.781924\n",
            "[206/500] Train Acc: 0.741911 Loss: 0.782862\n",
            "[207/500] Train Acc: 0.741461 Loss: 0.781749\n",
            "[208/500] Train Acc: 0.741903 Loss: 0.781218\n",
            "[209/500] Train Acc: 0.742363 Loss: 0.780443\n",
            "[210/500] Train Acc: 0.742005 Loss: 0.780897\n",
            "[211/500] Train Acc: 0.741664 Loss: 0.781308\n",
            "[212/500] Train Acc: 0.741317 Loss: 0.781954\n",
            "[213/500] Train Acc: 0.742494 Loss: 0.781420\n",
            "[214/500] Train Acc: 0.742046 Loss: 0.780438\n",
            "[215/500] Train Acc: 0.741834 Loss: 0.780785\n",
            "[216/500] Train Acc: 0.742225 Loss: 0.780175\n",
            "[217/500] Train Acc: 0.742264 Loss: 0.779878\n",
            "[218/500] Train Acc: 0.742359 Loss: 0.780800\n",
            "[219/500] Train Acc: 0.742058 Loss: 0.781137\n",
            "[220/500] Train Acc: 0.742097 Loss: 0.780920\n",
            "[221/500] Train Acc: 0.741941 Loss: 0.780652\n",
            "[222/500] Train Acc: 0.742200 Loss: 0.779054\n",
            "[223/500] Train Acc: 0.742274 Loss: 0.779916\n",
            "[224/500] Train Acc: 0.741803 Loss: 0.780887\n",
            "[225/500] Train Acc: 0.742540 Loss: 0.779976\n",
            "[226/500] Train Acc: 0.742141 Loss: 0.780185\n",
            "[227/500] Train Acc: 0.742148 Loss: 0.779759\n",
            "[228/500] Train Acc: 0.742931 Loss: 0.779392\n",
            "[229/500] Train Acc: 0.742778 Loss: 0.779419\n",
            "[230/500] Train Acc: 0.742317 Loss: 0.779809\n",
            "[231/500] Train Acc: 0.742944 Loss: 0.779004\n",
            "[232/500] Train Acc: 0.742122 Loss: 0.780648\n",
            "[233/500] Train Acc: 0.742900 Loss: 0.778673\n",
            "[234/500] Train Acc: 0.743064 Loss: 0.778801\n",
            "[235/500] Train Acc: 0.742874 Loss: 0.779591\n",
            "[236/500] Train Acc: 0.742621 Loss: 0.779608\n",
            "[237/500] Train Acc: 0.742958 Loss: 0.778436\n",
            "[238/500] Train Acc: 0.742566 Loss: 0.778886\n",
            "[239/500] Train Acc: 0.742721 Loss: 0.778845\n",
            "[240/500] Train Acc: 0.742767 Loss: 0.778917\n",
            "[241/500] Train Acc: 0.742757 Loss: 0.778480\n",
            "[242/500] Train Acc: 0.742748 Loss: 0.778486\n",
            "[243/500] Train Acc: 0.742661 Loss: 0.778154\n",
            "[244/500] Train Acc: 0.743142 Loss: 0.778779\n",
            "[245/500] Train Acc: 0.743122 Loss: 0.778391\n",
            "[246/500] Train Acc: 0.743266 Loss: 0.777759\n",
            "[247/500] Train Acc: 0.742685 Loss: 0.778636\n",
            "[248/500] Train Acc: 0.743044 Loss: 0.778650\n",
            "[249/500] Train Acc: 0.743203 Loss: 0.778159\n",
            "[250/500] Train Acc: 0.742717 Loss: 0.777610\n",
            "[251/500] Train Acc: 0.742783 Loss: 0.777703\n",
            "[252/500] Train Acc: 0.743039 Loss: 0.777149\n",
            "[253/500] Train Acc: 0.742559 Loss: 0.778308\n",
            "[254/500] Train Acc: 0.743180 Loss: 0.777424\n",
            "[255/500] Train Acc: 0.743264 Loss: 0.777279\n",
            "[256/500] Train Acc: 0.743126 Loss: 0.777155\n",
            "[257/500] Train Acc: 0.743556 Loss: 0.776830\n",
            "[258/500] Train Acc: 0.743309 Loss: 0.777036\n",
            "[259/500] Train Acc: 0.742826 Loss: 0.777169\n",
            "[260/500] Train Acc: 0.742976 Loss: 0.776590\n",
            "[261/500] Train Acc: 0.743575 Loss: 0.776804\n",
            "[262/500] Train Acc: 0.742955 Loss: 0.776779\n",
            "[263/500] Train Acc: 0.743276 Loss: 0.776087\n",
            "[264/500] Train Acc: 0.743123 Loss: 0.776498\n",
            "[265/500] Train Acc: 0.742860 Loss: 0.776541\n",
            "[266/500] Train Acc: 0.743240 Loss: 0.776350\n",
            "[267/500] Train Acc: 0.743481 Loss: 0.775476\n",
            "[268/500] Train Acc: 0.743639 Loss: 0.775866\n",
            "[269/500] Train Acc: 0.743291 Loss: 0.776370\n",
            "[270/500] Train Acc: 0.743147 Loss: 0.775671\n",
            "[271/500] Train Acc: 0.743983 Loss: 0.775429\n",
            "[272/500] Train Acc: 0.743244 Loss: 0.776306\n",
            "[273/500] Train Acc: 0.743480 Loss: 0.776074\n",
            "[274/500] Train Acc: 0.743216 Loss: 0.776826\n",
            "[275/500] Train Acc: 0.743444 Loss: 0.776386\n",
            "[276/500] Train Acc: 0.743855 Loss: 0.775103\n",
            "[277/500] Train Acc: 0.743690 Loss: 0.775347\n",
            "[278/500] Train Acc: 0.743557 Loss: 0.775303\n",
            "[279/500] Train Acc: 0.743373 Loss: 0.776280\n",
            "[280/500] Train Acc: 0.743579 Loss: 0.775022\n",
            "[281/500] Train Acc: 0.744071 Loss: 0.774209\n",
            "[282/500] Train Acc: 0.743981 Loss: 0.774174\n",
            "[283/500] Train Acc: 0.743620 Loss: 0.775488\n",
            "[284/500] Train Acc: 0.743996 Loss: 0.774442\n",
            "[285/500] Train Acc: 0.743307 Loss: 0.775204\n",
            "[286/500] Train Acc: 0.743335 Loss: 0.775493\n",
            "[287/500] Train Acc: 0.743680 Loss: 0.774232\n",
            "[288/500] Train Acc: 0.743777 Loss: 0.773862\n",
            "[289/500] Train Acc: 0.743943 Loss: 0.775327\n",
            "[290/500] Train Acc: 0.743727 Loss: 0.775061\n",
            "[291/500] Train Acc: 0.743899 Loss: 0.774829\n",
            "[292/500] Train Acc: 0.743663 Loss: 0.774727\n",
            "[293/500] Train Acc: 0.744342 Loss: 0.774111\n",
            "[294/500] Train Acc: 0.743983 Loss: 0.774382\n",
            "[295/500] Train Acc: 0.743260 Loss: 0.775317\n",
            "[296/500] Train Acc: 0.743423 Loss: 0.774696\n",
            "[297/500] Train Acc: 0.744091 Loss: 0.772747\n",
            "[298/500] Train Acc: 0.744596 Loss: 0.774085\n",
            "[299/500] Train Acc: 0.744156 Loss: 0.773105\n",
            "[300/500] Train Acc: 0.743996 Loss: 0.773491\n",
            "[301/500] Train Acc: 0.743820 Loss: 0.774702\n",
            "[302/500] Train Acc: 0.743926 Loss: 0.773196\n",
            "[303/500] Train Acc: 0.743813 Loss: 0.773612\n",
            "[304/500] Train Acc: 0.744031 Loss: 0.774547\n",
            "[305/500] Train Acc: 0.743987 Loss: 0.773849\n",
            "[306/500] Train Acc: 0.744244 Loss: 0.773333\n",
            "[307/500] Train Acc: 0.744596 Loss: 0.772593\n",
            "[308/500] Train Acc: 0.744269 Loss: 0.773261\n",
            "[309/500] Train Acc: 0.744164 Loss: 0.772711\n",
            "[310/500] Train Acc: 0.744355 Loss: 0.772943\n",
            "[311/500] Train Acc: 0.744287 Loss: 0.774425\n",
            "[312/500] Train Acc: 0.744118 Loss: 0.773423\n",
            "[313/500] Train Acc: 0.744556 Loss: 0.772555\n",
            "[314/500] Train Acc: 0.744233 Loss: 0.773057\n",
            "[315/500] Train Acc: 0.744709 Loss: 0.772196\n",
            "[316/500] Train Acc: 0.744562 Loss: 0.772011\n",
            "[317/500] Train Acc: 0.744712 Loss: 0.772136\n",
            "[318/500] Train Acc: 0.744512 Loss: 0.771390\n",
            "[319/500] Train Acc: 0.743434 Loss: 0.772455\n",
            "[320/500] Train Acc: 0.745022 Loss: 0.772034\n",
            "[321/500] Train Acc: 0.744390 Loss: 0.772239\n",
            "[322/500] Train Acc: 0.744600 Loss: 0.771836\n",
            "[323/500] Train Acc: 0.744587 Loss: 0.771320\n",
            "[324/500] Train Acc: 0.744404 Loss: 0.771832\n",
            "[325/500] Train Acc: 0.745084 Loss: 0.770659\n",
            "[326/500] Train Acc: 0.745003 Loss: 0.770443\n",
            "[327/500] Train Acc: 0.744276 Loss: 0.772413\n",
            "[328/500] Train Acc: 0.744229 Loss: 0.771555\n",
            "[329/500] Train Acc: 0.744922 Loss: 0.770724\n",
            "[330/500] Train Acc: 0.744734 Loss: 0.770919\n",
            "[331/500] Train Acc: 0.745060 Loss: 0.771331\n",
            "[332/500] Train Acc: 0.744522 Loss: 0.771577\n",
            "[333/500] Train Acc: 0.744137 Loss: 0.771401\n",
            "[334/500] Train Acc: 0.744290 Loss: 0.771390\n",
            "[335/500] Train Acc: 0.744843 Loss: 0.770804\n",
            "[336/500] Train Acc: 0.744579 Loss: 0.771417\n",
            "[337/500] Train Acc: 0.744985 Loss: 0.771108\n",
            "[338/500] Train Acc: 0.744248 Loss: 0.772279\n",
            "[339/500] Train Acc: 0.744576 Loss: 0.771254\n",
            "[340/500] Train Acc: 0.744863 Loss: 0.770415\n",
            "[341/500] Train Acc: 0.744691 Loss: 0.770943\n",
            "[342/500] Train Acc: 0.745150 Loss: 0.770144\n",
            "[343/500] Train Acc: 0.745331 Loss: 0.769453\n",
            "[344/500] Train Acc: 0.744752 Loss: 0.770046\n",
            "[345/500] Train Acc: 0.745144 Loss: 0.769622\n",
            "[346/500] Train Acc: 0.744729 Loss: 0.770729\n",
            "[347/500] Train Acc: 0.745252 Loss: 0.769884\n",
            "[348/500] Train Acc: 0.744791 Loss: 0.769946\n",
            "[349/500] Train Acc: 0.745100 Loss: 0.769833\n",
            "[350/500] Train Acc: 0.744969 Loss: 0.770019\n",
            "[351/500] Train Acc: 0.745387 Loss: 0.769320\n",
            "[352/500] Train Acc: 0.745001 Loss: 0.769911\n",
            "[353/500] Train Acc: 0.744736 Loss: 0.769827\n",
            "[354/500] Train Acc: 0.745470 Loss: 0.768841\n",
            "[355/500] Train Acc: 0.745370 Loss: 0.768817\n",
            "[356/500] Train Acc: 0.745421 Loss: 0.768949\n",
            "[357/500] Train Acc: 0.745265 Loss: 0.769325\n",
            "[358/500] Train Acc: 0.745182 Loss: 0.769478\n",
            "[359/500] Train Acc: 0.745400 Loss: 0.768510\n",
            "[360/500] Train Acc: 0.744718 Loss: 0.769500\n",
            "[361/500] Train Acc: 0.745446 Loss: 0.768774\n",
            "[362/500] Train Acc: 0.745485 Loss: 0.768682\n",
            "[363/500] Train Acc: 0.744956 Loss: 0.768835\n",
            "[364/500] Train Acc: 0.745332 Loss: 0.768283\n",
            "[365/500] Train Acc: 0.745867 Loss: 0.767956\n",
            "[366/500] Train Acc: 0.744827 Loss: 0.768990\n",
            "[367/500] Train Acc: 0.745239 Loss: 0.768876\n",
            "[368/500] Train Acc: 0.745223 Loss: 0.768233\n",
            "[369/500] Train Acc: 0.745659 Loss: 0.768687\n",
            "[370/500] Train Acc: 0.745703 Loss: 0.768468\n",
            "[371/500] Train Acc: 0.745545 Loss: 0.768237\n",
            "[372/500] Train Acc: 0.745757 Loss: 0.767978\n",
            "[373/500] Train Acc: 0.745061 Loss: 0.768122\n",
            "[374/500] Train Acc: 0.745722 Loss: 0.767813\n",
            "[375/500] Train Acc: 0.746018 Loss: 0.767400\n",
            "[376/500] Train Acc: 0.745450 Loss: 0.767714\n",
            "[377/500] Train Acc: 0.745540 Loss: 0.767420\n",
            "[378/500] Train Acc: 0.745688 Loss: 0.767354\n",
            "[379/500] Train Acc: 0.745757 Loss: 0.768032\n",
            "[380/500] Train Acc: 0.745341 Loss: 0.767341\n",
            "[381/500] Train Acc: 0.745523 Loss: 0.768247\n",
            "[382/500] Train Acc: 0.745857 Loss: 0.767992\n",
            "[383/500] Train Acc: 0.746105 Loss: 0.766972\n",
            "[384/500] Train Acc: 0.745486 Loss: 0.767889\n",
            "[385/500] Train Acc: 0.746049 Loss: 0.766995\n",
            "[386/500] Train Acc: 0.745717 Loss: 0.767066\n",
            "[387/500] Train Acc: 0.745238 Loss: 0.767742\n",
            "[388/500] Train Acc: 0.745812 Loss: 0.766994\n",
            "[389/500] Train Acc: 0.745950 Loss: 0.766804\n",
            "[390/500] Train Acc: 0.745568 Loss: 0.767535\n",
            "[391/500] Train Acc: 0.746129 Loss: 0.766397\n",
            "[392/500] Train Acc: 0.746771 Loss: 0.765972\n",
            "[393/500] Train Acc: 0.746063 Loss: 0.766735\n",
            "[394/500] Train Acc: 0.746448 Loss: 0.765763\n",
            "[395/500] Train Acc: 0.746050 Loss: 0.766077\n",
            "[396/500] Train Acc: 0.746154 Loss: 0.766125\n",
            "[397/500] Train Acc: 0.745500 Loss: 0.766228\n",
            "[398/500] Train Acc: 0.746650 Loss: 0.765135\n",
            "[399/500] Train Acc: 0.745905 Loss: 0.765847\n",
            "[400/500] Train Acc: 0.745936 Loss: 0.766301\n",
            "[401/500] Train Acc: 0.746332 Loss: 0.765610\n",
            "[402/500] Train Acc: 0.745942 Loss: 0.766388\n",
            "[403/500] Train Acc: 0.746007 Loss: 0.766257\n",
            "[404/500] Train Acc: 0.746103 Loss: 0.766065\n",
            "[405/500] Train Acc: 0.746690 Loss: 0.764635\n",
            "[406/500] Train Acc: 0.746073 Loss: 0.766228\n",
            "[407/500] Train Acc: 0.745918 Loss: 0.764990\n",
            "[408/500] Train Acc: 0.746211 Loss: 0.765396\n",
            "[409/500] Train Acc: 0.746375 Loss: 0.766003\n",
            "[410/500] Train Acc: 0.745600 Loss: 0.765997\n",
            "[411/500] Train Acc: 0.745909 Loss: 0.766503\n",
            "[412/500] Train Acc: 0.746815 Loss: 0.764874\n",
            "[413/500] Train Acc: 0.746258 Loss: 0.765287\n",
            "[414/500] Train Acc: 0.746645 Loss: 0.764840\n",
            "[415/500] Train Acc: 0.746282 Loss: 0.765168\n",
            "[416/500] Train Acc: 0.746113 Loss: 0.765457\n",
            "[417/500] Train Acc: 0.746608 Loss: 0.764449\n",
            "[418/500] Train Acc: 0.746206 Loss: 0.765090\n",
            "[419/500] Train Acc: 0.746783 Loss: 0.764905\n",
            "[420/500] Train Acc: 0.746295 Loss: 0.765460\n",
            "[421/500] Train Acc: 0.746566 Loss: 0.764772\n",
            "[422/500] Train Acc: 0.746651 Loss: 0.764008\n",
            "[423/500] Train Acc: 0.746706 Loss: 0.764465\n",
            "[424/500] Train Acc: 0.746669 Loss: 0.764679\n",
            "[425/500] Train Acc: 0.746242 Loss: 0.764940\n",
            "[426/500] Train Acc: 0.746594 Loss: 0.764573\n",
            "[427/500] Train Acc: 0.746937 Loss: 0.763848\n",
            "[428/500] Train Acc: 0.746238 Loss: 0.764272\n",
            "[429/500] Train Acc: 0.746527 Loss: 0.764248\n",
            "[430/500] Train Acc: 0.746207 Loss: 0.763632\n",
            "[431/500] Train Acc: 0.746161 Loss: 0.764712\n",
            "[432/500] Train Acc: 0.746464 Loss: 0.765003\n",
            "[433/500] Train Acc: 0.746553 Loss: 0.763664\n",
            "[434/500] Train Acc: 0.746651 Loss: 0.763995\n",
            "[435/500] Train Acc: 0.746351 Loss: 0.764638\n",
            "[436/500] Train Acc: 0.746396 Loss: 0.764196\n",
            "[437/500] Train Acc: 0.746522 Loss: 0.764734\n",
            "[438/500] Train Acc: 0.746655 Loss: 0.764169\n",
            "[439/500] Train Acc: 0.746652 Loss: 0.763550\n",
            "[440/500] Train Acc: 0.747820 Loss: 0.763073\n",
            "[441/500] Train Acc: 0.746985 Loss: 0.763276\n",
            "[442/500] Train Acc: 0.747209 Loss: 0.763007\n",
            "[443/500] Train Acc: 0.746625 Loss: 0.762928\n",
            "[444/500] Train Acc: 0.746958 Loss: 0.763409\n",
            "[445/500] Train Acc: 0.746831 Loss: 0.762749\n",
            "[446/500] Train Acc: 0.747296 Loss: 0.763326\n",
            "[447/500] Train Acc: 0.747013 Loss: 0.762573\n",
            "[448/500] Train Acc: 0.746602 Loss: 0.763263\n",
            "[449/500] Train Acc: 0.746480 Loss: 0.763436\n",
            "[450/500] Train Acc: 0.746806 Loss: 0.764643\n",
            "[451/500] Train Acc: 0.746973 Loss: 0.762729\n",
            "[452/500] Train Acc: 0.746764 Loss: 0.762720\n",
            "[453/500] Train Acc: 0.747197 Loss: 0.761996\n",
            "[454/500] Train Acc: 0.747194 Loss: 0.763411\n",
            "[455/500] Train Acc: 0.746637 Loss: 0.762662\n",
            "[456/500] Train Acc: 0.747094 Loss: 0.762021\n",
            "[457/500] Train Acc: 0.746498 Loss: 0.762926\n",
            "[458/500] Train Acc: 0.747318 Loss: 0.761542\n",
            "[459/500] Train Acc: 0.747419 Loss: 0.761679\n",
            "[460/500] Train Acc: 0.746949 Loss: 0.763349\n",
            "[461/500] Train Acc: 0.747497 Loss: 0.761508\n",
            "[462/500] Train Acc: 0.746927 Loss: 0.762479\n",
            "[463/500] Train Acc: 0.747042 Loss: 0.761766\n",
            "[464/500] Train Acc: 0.747345 Loss: 0.761708\n",
            "[465/500] Train Acc: 0.747320 Loss: 0.761646\n",
            "[466/500] Train Acc: 0.747280 Loss: 0.762169\n",
            "[467/500] Train Acc: 0.747469 Loss: 0.761124\n",
            "[468/500] Train Acc: 0.746850 Loss: 0.762163\n",
            "[469/500] Train Acc: 0.747229 Loss: 0.761839\n",
            "[470/500] Train Acc: 0.747361 Loss: 0.761169\n",
            "[471/500] Train Acc: 0.747330 Loss: 0.761305\n",
            "[472/500] Train Acc: 0.747456 Loss: 0.761317\n",
            "[473/500] Train Acc: 0.747380 Loss: 0.761368\n",
            "[474/500] Train Acc: 0.747462 Loss: 0.761251\n",
            "[475/500] Train Acc: 0.747673 Loss: 0.760309\n",
            "[476/500] Train Acc: 0.747213 Loss: 0.762519\n",
            "[477/500] Train Acc: 0.747797 Loss: 0.760427\n",
            "[478/500] Train Acc: 0.747624 Loss: 0.761199\n",
            "[479/500] Train Acc: 0.747423 Loss: 0.761375\n",
            "[480/500] Train Acc: 0.747200 Loss: 0.761159\n",
            "[481/500] Train Acc: 0.747584 Loss: 0.761165\n",
            "[482/500] Train Acc: 0.747637 Loss: 0.760865\n",
            "[483/500] Train Acc: 0.747707 Loss: 0.760236\n",
            "[484/500] Train Acc: 0.747968 Loss: 0.759352\n",
            "[485/500] Train Acc: 0.747549 Loss: 0.761344\n",
            "[486/500] Train Acc: 0.747475 Loss: 0.760743\n",
            "[487/500] Train Acc: 0.747858 Loss: 0.759423\n",
            "[488/500] Train Acc: 0.747334 Loss: 0.761489\n",
            "[489/500] Train Acc: 0.747613 Loss: 0.760227\n",
            "[490/500] Train Acc: 0.747875 Loss: 0.759944\n",
            "[491/500] Train Acc: 0.747597 Loss: 0.760237\n",
            "[492/500] Train Acc: 0.747675 Loss: 0.759829\n",
            "[493/500] Train Acc: 0.747375 Loss: 0.760692\n",
            "[494/500] Train Acc: 0.748087 Loss: 0.759281\n",
            "[495/500] Train Acc: 0.747432 Loss: 0.760699\n",
            "[496/500] Train Acc: 0.747383 Loss: 0.760262\n",
            "[497/500] Train Acc: 0.747381 Loss: 0.760339\n",
            "[498/500] Train Acc: 0.747514 Loss: 0.760653\n",
            "[499/500] Train Acc: 0.747546 Loss: 0.759528\n",
            "[500/500] Train Acc: 0.747753 Loss: 0.760065\n",
            "saving model at last epoch\n"
          ]
        }
      ],
      "source": [
        "# start training\n",
        "\n",
        "best_acc = 0.0\n",
        "Total_loss = []\n",
        "Total_acc = []\n",
        "for epoch in range(num_epoch):\n",
        "    if epoch == 0:\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    elif epoch == 35:\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # training\n",
        "    model.train() # set the model to training mode\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        outputs = model(inputs) \n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        batch_loss.backward() \n",
        "        optimizer.step() \n",
        "\n",
        "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                batch_loss = criterion(outputs, labels) \n",
        "                _, val_pred = torch.max(outputs, 1) \n",
        "            \n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
        "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
        "            ))\n",
        "\n",
        "            # if the model improves, save a checkpoint at this epoch\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
        "    else:\n",
        "        Total_acc.append(train_acc/len(train_set))\n",
        "        Total_loss.append(train_loss/len(train_loader))\n",
        "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
        "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
        "        ))\n",
        "\n",
        "# if not validating, save the last epoch\n",
        "if len(val_set) == 0:\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print('saving model at last epoch')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TNWz1L3RweQ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "598c7bd1-475d-40d8-f88f-6d26d1a1fe53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Training Loss\")\n",
        "plt.plot(Total_loss)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "# plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dnM9d0sswe7C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "e3eb13df-5e23-46b0-a249-79c6312ec1ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Training accuracy\")\n",
        "plt.plot(Total_acc)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "# plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfUECMFCn5VG"
      },
      "source": [
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QDbv5ysTepyl"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/CNNmodel_2.ckpt\" \"/content/drive/MyDrive/\"\n",
        "from google.colab import files\n",
        "# files.download(\"CNNmodel_500.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1PKjtAScPWtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cca22b-cf12-49d2-db01-6c108a234f2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# create testing dataset\n",
        "test_set = TIMITDataset(test, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# create model and load weights from checkpoint\n",
        "model = Classifier().to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "940TtCCdoYd0"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "84HU5GGjPqR0"
      },
      "outputs": [],
      "source": [
        "predict = []\n",
        "model.eval() # set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        inputs = data\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "        for y in test_pred.cpu().numpy():\n",
        "            predict.append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCxMZjK0sR2R"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for i in range(1, len(predict)-1):\n",
        "    step = 1\n",
        "    previous_ = predict[i-step]\n",
        "    next_ = predict[i+step]\n",
        "    current_ = predict[i]\n",
        "    if (previous_ != current_) and (next_ != current_) and (previous_ == next_):\n",
        "        print('idx',i,'correct', current_, 'to', previous_)\n",
        "        predict[i] = previous_\n",
        "        count +=1\n",
        "\n",
        "print('total number of correction %d, correction percent %.2f'% (count, count/len(predict)))\n",
        "\n",
        "for i in range(1, len(predict)-1):\n",
        "    step = 2\n",
        "    if i == 1 or i == len(predict)-2: step = 1\n",
        "    previous_ = predict[i-step]\n",
        "    next_ = predict[i+step]\n",
        "    current_ = predict[i]\n",
        "    if (previous_ != current_) and (next_ != current_) and (previous_ == next_):\n",
        "        print('idx',i,'correct', current_, 'to', previous_)\n",
        "        predict[i] = previous_\n",
        "        count +=1\n",
        "\n",
        "print('total number of correction %d, correction percent %.2f'% (count, count/len(predict)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWDf_C-omElb"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "source": [
        "with open('predictionCNN_2.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(predict):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "u6-drq6V8cBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9cdf5be-8665-49d4-f85d-a229dce6f859"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 0: `cp -r \"/content/predictionCNN_2.csv\" \"/content/drive/MyDrive/\"files.download(\"predictionCNN_500.csv\")'\n",
            "cp: cannot stat '/content/accuracy.png': No such file or directory\n",
            "cp: cannot stat \"/content/loss.png'\": No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp -r \"/content/predictionCNN_2.csv\" \"/content/drive/MyDrive/\"\\\n",
        "files.download(\"predictionCNN_500.csv\")\n",
        "!cp -r \"/content/accuracy.png\" \"/content/drive/MyDrive/\"\n",
        "!cp -r \"/content/loss.png'\" \"/content/drive/MyDrive/\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "CNN_(1) (4).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}